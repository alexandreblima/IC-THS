{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LeNet_CNN_mnist_tensorboard.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPa/1YTxVRt+eYj4gJoLse0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexandreblima/IC-THS/blob/master/LeNet_CNN_mnist_tensorboard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhOy1LRrWYJn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adaptação dos códigos do livro \"Deep Learning with TensorFlow2\n",
        "# and Keras: Regression, Convnets, GANs RNNs, NLP and more with\n",
        "# TensorFlow2 and the Keras API\", de Antonio Gulli, Amita Kapoor \n",
        "# e Sujit Pal, 2a ed., Packt. \n",
        "# código para TensorFlow 2.2.0 Spyder - Anaconda\n",
        "# autor: Alexandre B. de Lima\n",
        "# LeNet CNN - base de dados MNIST + TensorBoard\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models, optimizers\n",
        "import datetime\n",
        "print(tf.__version__)\n",
        "\n",
        "%load_ext tensorboard\n",
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/\n",
        "\n",
        "# Classe que define a rede LeNet\n",
        "class LeNet:\n",
        "\t@staticmethod\n",
        "\tdef build(input_shape, classes):\n",
        "\t\tmodel = models.Sequential()\n",
        "\t\t# CONV => RELU => POOL\n",
        "\t\tmodel.add(layers.Convolution2D(20, (5, 5), activation='relu',\n",
        "\t\t\tinput_shape=input_shape))\n",
        "\t\tmodel.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\t\t# CONV => RELU => POOL\n",
        "\t\tmodel.add(layers.Convolution2D(50, (5, 5), activation='relu'))\n",
        "\t\tmodel.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\t\t# Flatten => RELU layers\n",
        "\t\tmodel.add(layers.Flatten())\n",
        "\t\tmodel.add(layers.Dense(500, activation='relu'))\n",
        "\t\t# a softmax classifier\n",
        "\t\tmodel.add(layers.Dense(classes, activation=\"softmax\"))\n",
        "\t\treturn model\n",
        "\n",
        "# parâmetros da rede e do treinamento\n",
        "EPOCHS = 15\n",
        "BATCH_SIZE = 128\n",
        "VERBOSE = 1\n",
        "OPTIMIZER = tf.keras.optimizers.Adam()\n",
        "VALIDATION_SPLIT=0.90\n",
        "\n",
        "IMG_ROWS, IMG_COLS = 28, 28 # dimensões da imagem de entrada\n",
        "INPUT_SHAPE = (IMG_ROWS, IMG_COLS, 1)\n",
        "NB_CLASSES = 10  # número de saídas = número de dígitos\n",
        "\n",
        "# Carrega dados e rótulos\n",
        "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()\n",
        "\n",
        "# reformata dados para o formato array do numpy\n",
        "X_train = X_train.reshape((60000, 28, 28, 1))\n",
        "X_test = X_test.reshape((10000, 28, 28, 1))\n",
        "\n",
        "# normaliza dados\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "\n",
        "# representação numérica dos dados em ponto flutuante - 32 bits\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "# one-hot encode (vetorização) dos rótulos\n",
        "y_train = tf.keras.utils.to_categorical(y_train, NB_CLASSES)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, NB_CLASSES)\n",
        "\n",
        "# construção da rede\n",
        "model = LeNet.build(input_shape=INPUT_SHAPE, classes=NB_CLASSES)\n",
        "\n",
        "# compilação da rede\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=OPTIMIZER,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "\n",
        "# sumário da rede\n",
        "model.summary()\n",
        "\n",
        "# Tensorboard\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True)\n",
        "\n",
        "# treinamento\n",
        "history = model.fit(X_train, y_train, \n",
        "\t\tbatch_size=BATCH_SIZE, epochs=EPOCHS, \n",
        "\t\tverbose=VERBOSE, validation_split=VALIDATION_SPLIT,\n",
        "\t\tcallbacks=tensorboard_callback)\n",
        "\n",
        "# resultados: custo (loss) e acurácia - TESTE \n",
        "score = model.evaluate(X_test, y_test, verbose=VERBOSE)\n",
        "print(\"\\nTest score:\", score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3Qaoh3CfmHg",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    }
  ]
}