{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LeNet_CNN_mnist_tensorboard.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM94cIdKwBfiyqFrQX6Mwuq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexandreblima/IC-THS/blob/master/LeNet_CNN_mnist_tensorboard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhOy1LRrWYJn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# arquivo: LeNet_CNN_mnist_tensorboard.py\n",
        "# Adaptação dos códigos do livro \"Deep Learning with TensorFlow2\n",
        "# and Keras: Regression, Convnets, GANs RNNs, NLP and more with\n",
        "# TensorFlow2 and the Keras API\", de Antonio Gulli, Amita Kapoor \n",
        "# e Sujit Pal, 2a ed., Packt. \n",
        "# código para TensorFlow 2.2.0 Spyder - Anaconda\n",
        "# LeNet CNN - base de dados MNIST\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models, optimizers\n",
        "import datetime\n",
        "print(tf.__version__)\n",
        "\n",
        "%load_ext tensorboard\n",
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/\n",
        "\n",
        "# Classe que define a rede LeNet\n",
        "class LeNet:\n",
        "\t@staticmethod\n",
        "\tdef build(input_shape, classes):\n",
        "\t\tmodel = models.Sequential()\n",
        "\t\t# CONV => RELU => POOL\n",
        "\t\tmodel.add(layers.Convolution2D(20, (5, 5), activation='relu',\n",
        "\t\t\tinput_shape=input_shape))\n",
        "\t\tmodel.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\t\t# CONV => RELU => POOL\n",
        "\t\tmodel.add(layers.Convolution2D(50, (5, 5), activation='relu'))\n",
        "\t\tmodel.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\t\t# Flatten => RELU layers\n",
        "\t\tmodel.add(layers.Flatten())\n",
        "\t\tmodel.add(layers.Dense(500, activation='relu'))\n",
        "\t\t# a softmax classifier\n",
        "\t\tmodel.add(layers.Dense(classes, activation=\"softmax\"))\n",
        "\t\treturn model\n",
        "\n",
        "# parâmetros da rede e do treinamento\n",
        "EPOCHS = 15\n",
        "BATCH_SIZE = 128\n",
        "VERBOSE = 1\n",
        "OPTIMIZER = tf.keras.optimizers.Adam()\n",
        "VALIDATION_SPLIT=0.90\n",
        "\n",
        "IMG_ROWS, IMG_COLS = 28, 28 # dimensões da imagem de entrada\n",
        "INPUT_SHAPE = (IMG_ROWS, IMG_COLS, 1)\n",
        "NB_CLASSES = 10  # número de saídas = número de dígitos\n",
        "\n",
        "# Carrega dados e rótulos\n",
        "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()\n",
        "\n",
        "# reformata dados para o formato array do numpy\n",
        "X_train = X_train.reshape((60000, 28, 28, 1))\n",
        "X_test = X_test.reshape((10000, 28, 28, 1))\n",
        "\n",
        "# normaliza dados\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "\n",
        "# representação numérica dos dados em ponto flutuante - 32 bits\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "# one-hot encode (vetorização) dos rótulos\n",
        "y_train = tf.keras.utils.to_categorical(y_train, NB_CLASSES)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, NB_CLASSES)\n",
        "\n",
        "# construção da rede\n",
        "model = LeNet.build(input_shape=INPUT_SHAPE, classes=NB_CLASSES)\n",
        "\n",
        "# compilação da rede\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=OPTIMIZER,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "\n",
        "# sumário da rede\n",
        "model.summary()\n",
        "\n",
        "# Tensorboard\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True)\n",
        "\n",
        "# treinamento\n",
        "treino = model.fit(X_train, y_train, \n",
        "\t\tbatch_size=BATCH_SIZE, epochs=EPOCHS, \n",
        "\t\tverbose=VERBOSE, validation_split=VALIDATION_SPLIT,\n",
        "\t\tcallbacks=tensorboard_callback)\n",
        "\n",
        "treino_dic = treino.history \n",
        "# \"treino.history\" retorna um contêiner de dicionário (uma generalização do conceito de lista): tipo \"dict\" \n",
        "# Um dicionário contém pares de (chave, valor)\n",
        "treino_dic.keys()\n",
        "# chaves no tf 2.1.0: ['loss', 'accuracy', 'val_loss', 'val_accuracy']\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "font = {'family': 'serif',\n",
        "        'color':  'darkred',\n",
        "        'weight': 'normal',\n",
        "        'size': 16,\n",
        "        }\n",
        "\n",
        "acc = treino.history['accuracy']\n",
        "val_acc = treino.history['val_accuracy']\n",
        "loss = treino.history['loss']\n",
        "val_loss = treino.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.clf()\n",
        "\n",
        "plt.plot(epochs, acc, 'b', label='Acurácia de treinamento')\n",
        "plt.plot(epochs, val_acc, 'r', label='Acurácia de validação')\n",
        "plt.title('Curvas de aprendizado', fontdict=font)\n",
        "plt.xlabel('tempo (épocas)', fontdict=font)\n",
        "plt.ylabel('Acurácia', fontdict=font)\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'b', label='Erro de treinamento')\n",
        "plt.plot(epochs, val_loss, 'r', label='Erro de validação')\n",
        "plt.title('Curvas de aprendizado ', fontdict=font)\n",
        "plt.xlabel('tempo (épocas)', fontdict=font)\n",
        "plt.ylabel('Erro', fontdict=font)\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# resultados: custo (loss) e acurácia - TESTE \n",
        "score = model.evaluate(X_test, y_test, verbose=VERBOSE)\n",
        "print(\"\\nTest score:\", score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3Qaoh3CfmHg",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    }
  ]
}