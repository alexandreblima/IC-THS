{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_0_sgd_epoch200_batch128_2layers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP28SObBl/0vUp/ZtJjagNm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexandreblima/IC-THS/blob/master/mnist_0_sgd_epoch200_batch128_2layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FffrDSgSZt98",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ7bnGfkZyF9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# arquivo: mnist_0_sgd_epoch200_batch128_2layers.py   \n",
        "# Adaptação dos códigos do livro \"Deep Learning with TensorFlow2\n",
        "# and Keras: Regression, Convnets, GANs RNNs, NLP and more with\n",
        "# TensorFlow2 and the Keras API, de Antonio Gulli, Amita Kapoor \n",
        "# e Sujit Pal, 2a ed., Packt. \n",
        "# otimizador = SGD\n",
        "# código para TensorFlow 2\n",
        "\n",
        "# Uso do TensorFlow 2 para definir uma rede que reconhece dígitos \n",
        "# manuscritos MNIST (http://yann.lecun.com/exdb/mnist/)\n",
        "# O MNIST é um banco de dados de dígitos manuscritos compostos de um conjunto \n",
        "# de treinamento de 60.000 exemplos (amostras) e um conjunto de testes de 10.000 exemplos. \n",
        "# Os exemplos de treinamento são anotados por humanos com a resposta correta. \n",
        "# Por exemplo, se o dígito manuscrito for o número \"3\", \"3\" será o rótulo (label) \n",
        "# associado a esse exemplo. Cada imagem MNIST está codificada em escala de cinza e \n",
        "# consiste em uma matriz de 28 x 28 pixels, em que cada pixel é um número inteiro \n",
        "# na faixa [0, 255]\n",
        "\n",
        "# Seguindo o estilo Keras, o TensorFlow 2 fornece bibliotecas adequadas \n",
        "# (https://www.tensorflow.org/api_docs/python/tf/keras/datasets) para carregar o \n",
        "# conjunto de dados e dividi-lo em conjuntos de treinamento, X_train, usado para \n",
        "# ajustar a rede e conjuntos de testes, X_test, usados para avaliar o desempenho. \n",
        "# Os dados são convertidos em float32 para usar precisão de 32 bits ao treinar uma rede \n",
        "# neural e normalizados para o intervalo [0, 1]. Além disso, carregamos os rótulos \n",
        "# verdadeiros em Y_train e Y_test, respectivamente, e executamos uma codificação \n",
        "# \"one-hot\" neles. \n",
        "# Exemplo de codificação one-hot do dígito 3 (feature categórica ou não-numérica)\n",
        "# em um vetor com 10 elementos v = [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "import tensorflow as tf\n",
        "#import numpy as np\n",
        "from tensorflow import keras\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "import datetime\n",
        "\n",
        "%load_ext tensorboard\n",
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/\n",
        "\n",
        "# Parâmetros da rede e de treinamento\n",
        "epocas = 200   # define a duração do treinamento\n",
        "lote_tam = 128 # número de amostras que alimentarão a rede em uma dada época\n",
        "               # de treinamento (em inglês, lote = batch)\n",
        "verbose = 1\n",
        "n_classes = 10 # número de saídas = número de dígitos\n",
        "n_oculta = 128 \n",
        "val_split = 0.2 # a fração do número de amostras de treinamento reservadas para\n",
        "                # validação => 48.000 amostras para treino + 12.000 amostras para \n",
        "                # validação = 60.000 exemplos do conjunto de treinamento MNIST     \n",
        "\n",
        "# carrega a base de dados MNIST\n",
        "mnist = keras.datasets.mnist\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "\n",
        "# Em Python, uma lista é uma sequência de objetos separados por vírgulas. \n",
        "# Os objetos podem ser de qualquer tipo: números, strings e até mesmo outras listas. \n",
        "# Por exemplo, digite a linha seguinte no Console:\n",
        "# animais = ['peixe', 'gato', 'cão']\n",
        "# A variável \"animais\" é uma lista de objetos de string\n",
        "# Indexação dos itens da lista \"animais\":\n",
        "# Digite as seguintes linhas no Console\n",
        "# animais[0]\n",
        "# animais[1]\n",
        "# animais[2]\n",
        "# animais[-3]\n",
        "# animais[-2]\n",
        "# animais[-1]\n",
        "\n",
        "# X_train, Y_train, X_test e Y_test são listas numéricas designadas por \"array\". \n",
        "# X_train possui 60.000 imagens de dígitos manuscritos. Cada imagem está em escala \n",
        "# de cinza e consiste em uma matriz de 28 x 28 pixels, em que cada pixel é um número \n",
        "# inteiro na faixa [0, 255] (representação com 8 bits). O mesmo se aplica a X_test.\n",
        "\n",
        "# X_train e X_test serão reformatados para 60.000 x 784 (28 x 28 = 784)\n",
        "# Ou seja, X_train e X_test serão \"vetorizados\" para o formato de vetor x de tamanho 784 × 1;\n",
        "\n",
        "reformat = 784 # é a dimensão do espaço de \"features\"\n",
        "               # ou seja, a camada de entrada possui 784 \"input units\"\n",
        "               # Uma entrada é um vetor coluna 784 x 1\n",
        " \n",
        "X_train = X_train.reshape(60000, reformat) \n",
        "X_test = X_test.reshape(10000, reformat) # \"reshape\" é um método de \"numpy.ndarray\"\n",
        "                                         # que retorna um \"array\" que contém os mesmos\n",
        "                                         # dados, só que em um outro formato\n",
        "\n",
        "# A representação dos números contidos nos \"arrays\" X_train e X_test será convertida\n",
        "# para codificação em ponto flutuante com 32 bits. Para maiores detalhes, consulte:\n",
        "# http://www.ic.uff.br/~simone/scminter/contaulas/6_FLOAT.pdf \n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# normalização em [0,1]\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "print(X_train.shape[0], 'amostras de treinamento')\n",
        "print(X_test.shape[0], 'amostras de teste')\n",
        "\n",
        "# Representação \"one-hot\" dos rótulos (labels) de treinamento e teste\n",
        "Y_train = tf.keras.utils.to_categorical(Y_train, n_classes)\n",
        "Y_test = tf.keras.utils.to_categorical(Y_test, n_classes)\n",
        "\n",
        "# construção do modelo\n",
        "# A camada de saída é composta por 10 neurônios com função de ativação \"softmax\", que é uma \n",
        "# generalização da função sigmóide ou logística. \n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(keras.layers.Dense(n_classes, input_shape=(reformat,), kernel_initializer='zeros', name='dense_layer', activation='softmax'))\n",
        "\n",
        "# sumário do modelo\n",
        "model.summary()\n",
        "\n",
        "# Depois de definir o modelo, precisamos compilá-lo para que ele possa ser executado pelo TensorFlow 2\n",
        "\n",
        "# Opções a serem feitas durante a compilação. \n",
        "\n",
        "# 1) Selecionar um otimizador, que é o algoritmo específico usado para atualizar os pesos da rede enquanto treinamos o modelo. \n",
        "# vide: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\n",
        "\n",
        "# 2) Selecionar uma função objetivo, que é usada pelo otimizador para navegar no espaço de pesos. \n",
        "# Nota: frequentemente, a função objetivo é designada por função de perda (\"loss function\") ou função de custo, \n",
        "# sendo o processo de otimização definido como um processo de minimização de perda (erro). \n",
        "# vide: https://www.tensorflow.org/api_docs/python/tf/keras/losses\n",
        "\n",
        "# 3) Avaliar o modelo treinado.\n",
        "\n",
        "# compilando o modelo\n",
        "model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# O otimizador \"Stochastic Gradient Descent\" (SGD), ou Gradiente Descendente Estocástico\n",
        "# uma forma de acelerar o treinamento é utilizando métodos que oferecem aproximações do Grandiente Descendente, \n",
        "# por exemplo usando amostras aleatórias dos dados ao invés de analisar todas as instâncias existentes. \n",
        "# Por esse motivo, o nome desse método é Gradiente Descendente Estocástico, já que ao invés de analisar \n",
        "# todos os dados disponíveis, analisa-se apenas uma amostra, e dessa forma, adiciona-se aleatoriedade ao processo. \n",
        "# Também é possível calcular o Gradiente Descendente usando apenas uma instância por vez \n",
        "# (método mais utilizado para analisar fluxos de dados ou aprendizagem online). Na prática, o mais comum é utilizar \n",
        "# os chamados mini-batches (amostra aleatória dos dados) com um tamanho fixo B. Após executar diversas iterações \n",
        "# (sendo que cada iteração irá adaptar os parâmetros usando as instâncias no mini-batch atual), espera-se \n",
        "# obter uma aproximação do método do Gradiente Descendente.\n",
        "\n",
        "# Algumas opções comuns para a função de perda são:\n",
        "# Mean Square Error (MSE), que define o erro médio quadrático entre as previsões e os valores reais. \n",
        "# \"categorical_crossentropy\", que define a perda logarítmica multiclasse.\n",
        "# \"binary_crossentropy\", que define a perda logarítmica binária.\n",
        "\n",
        "# As métricas são semelhantes às funções de perda, com a única diferença de que elas não são usadas para treinar um modelo, \n",
        "# mas apenas para avaliar o modelo. Algumas escolhas comuns para a métrica:\n",
        "# Acurácia: calcula com que frequência as previsões são iguais aos rótulos.\n",
        "# Precisão: define quantos itens selecionados são relevantes para uma classificação multi-rótulo. \n",
        "# vide: https://www.tensorflow.org/api_docs/python/tf/keras/metrics\n",
        "\n",
        "# Depois que o modelo é compilado, ele pode ser treinado com o método fit(), que especifica alguns parâmetros:\n",
        "# - epochs (época): é o número de vezes que o modelo é exposto ao conjunto de treinamento. A cada iteração, o otimizador \n",
        "# tenta ajustar os pesos para que a função custo seja minimizada.\n",
        "# - batch_size (tamanho do lote): é o número de instâncias de treinamento observadas antes do otimizador executar \n",
        "# uma atualização de peso; geralmente há muitos lotes por época.\n",
        "\n",
        "# Tensorboard\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True)\n",
        "\n",
        "# treinamento do modelo no TensorFlow 2\n",
        "treino = model.fit(X_train, Y_train, batch_size=lote_tam, epochs=epocas, verbose=verbose, validation_split=val_split, callbacks=tensorboard_callback)\n",
        "# model.fit retorna o objeto \"treino\", que é do tipo \"History\".  \n",
        "\n",
        "treino_dic = treino.history \n",
        "# \"treino.history\" retorna um contêiner de dicionário (uma generalização do conceito de lista): tipo \"dict\" \n",
        "# Um dicionário contém pares de (chave, valor)\n",
        "treino_dic.keys()\n",
        "# chaves no tf 2.1.0: ['loss', 'accuracy', 'val_loss', 'val_accuracy']\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "font = {'family': 'serif',\n",
        "        'color':  'darkred',\n",
        "        'weight': 'normal',\n",
        "        'size': 16,\n",
        "        }\n",
        "\n",
        "acc = treino.history['accuracy']\n",
        "val_acc = treino.history['val_accuracy']\n",
        "loss = treino.history['loss']\n",
        "val_loss = treino.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.clf()\n",
        "\n",
        "plt.plot(epochs, acc, 'b', label='Acurácia de treinamento')\n",
        "plt.plot(epochs, val_acc, 'r', label='Acurácia de validação')\n",
        "plt.title('Curvas de aprendizado', fontdict=font)\n",
        "plt.xlabel('tempo (épocas)', fontdict=font)\n",
        "plt.ylabel('Acurácia', fontdict=font)\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'b', label='Erro de treinamento')\n",
        "plt.plot(epochs, val_loss, 'r', label='Erro de validação')\n",
        "plt.title('Curvas de aprendizado ', fontdict=font)\n",
        "plt.xlabel('tempo (épocas)', fontdict=font)\n",
        "plt.ylabel('Erro', fontdict=font)\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# avaliação do modelo\n",
        "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
        "print('Acurácia do teste:', test_acc)\n",
        "\n",
        "# previsões\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbeLjaDMZ0EI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}