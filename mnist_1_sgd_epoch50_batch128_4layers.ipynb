{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "mnist_1_sgd_epoch50_batch128_4layers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexandreblima/IC-THS/blob/master/mnist_1_sgd_epoch50_batch128_4layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YacoeVhbI71",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# arquivo: mnist_1_sgd_epoch50_batch128_4layers.py\n",
        "# Adaptação dos códigos do livro \"Deep Learning with TensorFlow2\n",
        "# and Keras: Regression, Convnets, GANs RNNs, NLP and more with\n",
        "# TensorFlow2 and the Keras API, de Antonio Gulli, Amita Kapoor \n",
        "# e Sujit Pal, 2a ed., Packt. \n",
        "# otimizador = SGD\n",
        "# código para TensorFlow 2\n",
        "\n",
        "import tensorflow as tf\n",
        "#import numpy as np\n",
        "from tensorflow import keras\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "import datetime\n",
        "\n",
        "%load_ext tensorboard\n",
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/\n",
        "\n",
        "# Parâmetros da rede e de treinamento\n",
        "epocas = 50   # define a duração do treinamento\n",
        "lote_tam = 128 # número de amostras que alimentarão a rede em uma dada época\n",
        "               # de treinamento (em inglês, lote = batch)\n",
        "verbose = 1\n",
        "n_classes = 10 # número de saídas = número de dígitos\n",
        "n_oculta = 128 \n",
        "val_split = 0.2 # a fração do número de amostras de treinamento reservadas para\n",
        "                # validação => 48.000 amostras para treino + 12.000 amostras para \n",
        "                # validação = 60.000 exemplos do conjunto de treinamento MNIST     \n",
        "\n",
        "# carrega a base de dados MNIST\n",
        "mnist = keras.datasets.mnist\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "\n",
        "reformat = 784 # é a dimensão do espaço de \"features\"\n",
        "               # ou seja, a camada de entrada possui 784 \"input units\"\n",
        "               # Uma entrada é um vetor coluna 784 x 1\n",
        " \n",
        "X_train = X_train.reshape(60000, reformat) \n",
        "X_test = X_test.reshape(10000, reformat) \n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# normalização em [0,1]\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "print(X_train.shape[0], 'amostras de treinamento')\n",
        "print(X_test.shape[0], 'amostras de teste')\n",
        "\n",
        "# Representação \"one-hot\" dos rótulos (labels) de treinamento e teste\n",
        "Y_train = tf.keras.utils.to_categorical(Y_train, n_classes)\n",
        "Y_test = tf.keras.utils.to_categorical(Y_test, n_classes)\n",
        "\n",
        "# construção do modelo\n",
        "# A camada de saída é composta por 10 neurônios com função de ativação \"softmax\", que é uma \n",
        "# generalização da função sigmóide ou logística. \n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(keras.layers.Dense(n_oculta, input_shape=(reformat,), name='dense_layer1', activation='relu'))\n",
        "model.add(keras.layers.Dense(n_oculta, input_shape=(reformat,), name='dense_layer2', activation='relu'))\n",
        "model.add(keras.layers.Dense(n_classes, input_shape=(reformat,), name='dense_layer3', activation='softmax'))\n",
        "\n",
        "# sumário do modelo\n",
        "model.summary()\n",
        "\n",
        "# compilando o modelo\n",
        "model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Tensorboard\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True)\n",
        "\n",
        "# treinamento do modelo no TensorFlow 2\n",
        "treino = model.fit(X_train, Y_train, batch_size=lote_tam, epochs=epocas, verbose=verbose, validation_split=val_split, callbacks=tensorboard_callback)\n",
        "# model.fit retorna o objeto \"treino\", que é do tipo \"History\".  \n",
        "\n",
        "treino_dic = treino.history \n",
        "# \"treino.history\" retorna um contêiner de dicionário (uma generalização do conceito de lista): tipo \"dict\" \n",
        "# Um dicionário contém pares de (chave, valor)\n",
        "treino_dic.keys()\n",
        "# chaves no tf 2.1.0: ['loss', 'accuracy', 'val_loss', 'val_accuracy']\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "font = {'family': 'serif',\n",
        "        'color':  'darkred',\n",
        "        'weight': 'normal',\n",
        "        'size': 16,\n",
        "        }\n",
        "\n",
        "acc = treino.history['accuracy']\n",
        "val_acc = treino.history['val_accuracy']\n",
        "loss = treino.history['loss']\n",
        "val_loss = treino.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.clf()\n",
        "\n",
        "plt.plot(epochs, acc, 'b', label='Acurácia de treinamento')\n",
        "plt.plot(epochs, val_acc, 'r', label='Acurácia de validação')\n",
        "plt.title('Curvas de aprendizado', fontdict=font)\n",
        "plt.xlabel('tempo (épocas)', fontdict=font)\n",
        "plt.ylabel('Acurácia', fontdict=font)\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'b', label='Erro de treinamento')\n",
        "plt.plot(epochs, val_loss, 'r', label='Erro de validação')\n",
        "plt.title('Curvas de aprendizado ', fontdict=font)\n",
        "plt.xlabel('tempo (épocas)', fontdict=font)\n",
        "plt.ylabel('Erro', fontdict=font)\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# avaliação do modelo\n",
        "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
        "print('Acurácia do teste:', test_acc)\n",
        "# resultado esperado: por volta de 96% \n",
        "\n",
        "# previsões\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgN5Oeh-bI78",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}